from flask import Flask, render_template, request, jsonify
import openai
import spacy
import os

app = Flask(__name__)

# OpenAI API key setup
openai.api_key = os.getenv('OPENAI_API_KEY')

# Load spaCy language model
nlp = spacy.load("en_core_web_sm")


class CaseStudy:
    def __init__(self, title, details, questions):
        self.title = title
        self.details = details
        self.questions = questions


# Example case study initialization
case_study_info = CaseStudy(
    title="Renewable Energy Project in Rural Areas",
    details=(
        "This case study focuses on the development of a renewable energy project "
        "aimed at providing sustainable, reliable, and cost-effective power solutions "
        "to rural communities. The project explores the feasibility, planning, "
        "implementation, and maintenance of renewable energy installations, "
        "including solar panels and wind turbines, to enhance the energy security "
        "and improve the quality of life for rural inhabitants. Special attention "
        "is given to community involvement, environmental impact assessments, "
        "and the integration of renewable energy sources into existing power grids."
    ),
    questions={
        "planning": (
            "The planning phase involves assessing the energy needs of the rural area, "
            "identifying the most suitable renewable energy sources, conducting feasibility "
            "studies, and engaging with the community to ensure the project aligns with local "
            "needs and expectations. Key considerations include site selection, environmental "
            "impact assessments, and securing funding."
        ),
        "implementation": (
            "Implementation includes the procurement and installation of solar panels and wind turbines, "
            "setting up electrical infrastructure to connect the renewable energy sources to the power grid, "
            "and ensuring compliance with local and national regulations. Training for local technicians on "
            "operation and maintenance of the installations is also a critical component to ensure sustainability."
        ),
        "community_involvement": (
            "Community involvement is crucial for the success and acceptance of renewable energy projects. "
            "This involves educating the community on the benefits of renewable energy, involving them in "
            "decision-making processes, and potentially training local residents to manage and maintain "
            "the energy installations. Effective communication and stakeholder engagement strategies "
            "are key to building trust and support."
        ),
        "environmental_impact": (
            "Assessing and mitigating the environmental impact of renewable energy installations is vital "
            "to ensure the sustainability of the project. This includes evaluating the potential effects on "
            "local wildlife, water sources, and vegetation, and implementing measures to minimize negative "
            "impacts. Ongoing environmental monitoring is also essential to address any unforeseen issues."
        ),
        "maintenance_and_sustainability": (
            "Ensuring the long-term maintenance and sustainability of renewable energy installations involves "
            "regular inspections, servicing, and repair work, which can be facilitated by training local technicians. "
            "Sustainability also includes evaluating the economic, social, and environmental benefits of the project "
            "over time, adjusting strategies as needed to address challenges and capitalize on new opportunities."
        )
    }
)



def is_question_relevant_nlp(question, context):
    # Convert question and context to spaCy doc objects
    doc_question = nlp(question)
    doc_context = nlp(context)
    # Calculate similarity
    similarity = doc_question.similarity(doc_context)
    # Define a threshold for relevancy; adjust based on your needs
    return similarity > 0.5


@app.route('/')
def home():
    return render_template('index.html')


@app.route('/ask', methods=['POST'])
def ask():
    user_message = request.form['message']
    # Check question relevance using spaCy
    context = case_study_info.details  # You could include more context as needed
    if not is_question_relevant_nlp(user_message, context):
        return jsonify({"message": "Please ask a question related to the case study."})

    # If relevant, proceed with generating a response using OpenAI's GPT-3
    prompt = f"Case Study Title: {case_study_info.title}\nDetails: {case_study_info.details}\n\nQuestion: {user_message}\nAnswer:"
    response = openai.Completion.create(
        engine="text-davinci-003",
        prompt=prompt,
        temperature=0.7,
        max_tokens=150,
        top_p=1.0,
        frequency_penalty=0.0,
        presence_penalty=0.0,
        stop=["\n"]
    )

    bot_response = response.choices[0].text.strip()
    return jsonify({"message": bot_response})


if __name__ == "__main__":
    app.run(debug=True)





















APP 2



from flask import Flask, render_template, request, jsonify
from openai import OpenAI
import os

client = OpenAI()
app = Flask(__name__)

# Ensure you set your OpenAI API key correctly
# openai.api_key = os.getenv('OPENAI_API_KEY')


@app.route('/')
def home():
    return render_template('index.html')


@app.route('/ask', methods=['POST'])
def ask():
    user_message = request.form['message']

    # Adjusted API call to use ChatCompletion.create
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",  # You can choose the model best suited for your needs
            messages=[
                {"role": "system",
                 "content": "You are a helpful assistant knowledgeable about renewable energy projects in rural areas."},
                {"role": "user", "content": user_message}
            ]
        )
    except Exception as e:
        # Handle exceptions (e.g., API errors) and potentially log them
        print(f"Error generating response: {e}")
        return jsonify({"message": "Sorry, I couldn't process your request."}), 500

    # Extract the chatbot's response
    bot_response = response.choices[0].message[
        "content"] if response.choices else "Sorry, I couldn't generate a response."

    return jsonify({"message": bot_response})


if __name__ == "__main__":
    app.run(debug=True)


















































from flask import Flask, render_template, request, jsonify, session, url_for, redirect
from openai import OpenAI
import os
import json
from datetime import datetime



app = Flask(__name__)

# Initialize the OpenAI client
client = OpenAI()

# Set the secret key for session management to something random
app.secret_key = os.urandom(24)

# Define relevant keywords for the case study
RELEVANT_KEYWORDS = [
    "renewable energy", "solar panels", "wind turbines", "rural", "sustainability",
    "planning", "implementation", "community involvement", "environmental impact", "maintenance",
    "energy needs", "feasibility", "funding options", "technological advancements", "long-term sustainability"
]

@app.route('/')
def home():
    session['question_count'] = 0
    return render_template('index.html')

@app.route('/ask', methods=['POST'])
def ask():
    # Initialize question count if it doesn't exist
    if 'question_count' not in session:
        session['question_count'] = 0
    if 'chat_log' not in session:
        session['chat_log'] = []

    is_final_answer = request.form.get('isFinalAnswer') == 'true'

    # Check if the user has reached the question limit
    if session['question_count'] >= 15:
        return jsonify({"message": "You have reached the limit of 15 questions."})

    user_message = request.form['message']
    # Append the user's message to the session chat log
    session['chat_log'].append({'sender': 'user', 'message': user_message})
    # Check if the question is relevant
    if not is_question_relevant(user_message):
        "Please ask a question that is relevant to the renewable energy project in rural areas."
        return jsonify({"message": "Please ask a question that is relevant to the renewable energy project in rural areas."})

    # Increment the question count
    session['question_count'] += 1

    system_message = ("You are interviewing a student you are the client in a case about renewable energy."
                      "here is all the information for the case"
                      "This case study focuses on the development of a renewable energy project "
                      "aimed at providing sustainable, reliable, and cost-effective power solutions "
                      "to rural communities. The project explores the feasibility, planning, "
                      "implementation, and maintenance of renewable energy installations, "
                      "including solar panels and wind turbines, to enhance the energy security "
                      "and improve the quality of life for rural inhabitants. Special attention "
                      "is given to community involvement, environmental impact assessments, "
                      "and the integration of renewable energy sources into existing power grids."
                      "Final note, you are the client, the interview already began be concise and precise"
                      "simulate real-life situation."
                      )
    # Just start here

    # End here
    try:
        completion = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": system_message},
                {"role": "user", "content": user_message}
            ]
        )
    except Exception as e:
        print(f"Error generating response from OpenAI: {e}")
        return jsonify({"message": "Sorry, I couldn't process your request at the moment."}), 500

    if completion.choices:
        bot_response = completion.choices[0].message.content
    else:
        bot_response = "Sorry, I couldn't generate a response."

    return jsonify({"message": bot_response})


@app.route('/submit_final')
def submit_final():
    return render_template('submit_final.html')

@app.route('/process_final_answer', methods=['POST'])
def process_final_answer():
    final_answer = request.form['finalAnswer']
    chat_log = session.get('chat_log', [])
    chat_log.append({'sender': 'user', 'message': final_answer, 'final': True})
    session['chat_log'] = chat_log
    save_chat_log_to_file(chat_log)
    return redirect(url_for('confirmation'))

@app.route('/confirmation')
def confirmation():
    # Simple confirmation page indicating successful submission
    return "Thank you for your submission."

def save_chat_log_to_file(chat_log):
    os.makedirs('chat_logs', exist_ok=True)  # Ensure the directory exists
    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
    filename = f"chat_logs/chat_log_{timestamp}.json"
    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(chat_log, f, indent=4)

def is_question_relevant(question):
    question_lower = question.lower()
    return any(keyword in question_lower for keyword in RELEVANT_KEYWORDS)

if __name__ == "__main__":
    app.run(debug=True)
